{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f7d06a-904c-48e1-8802-d8edc1b36e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trained LSTM weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# =====================CONFIG======================\n",
    "STEPS_PER_REP = 4\n",
    "NUM_REPS = 3\n",
    "FRAME_SKIP = 10\n",
    "LSTM_HIDDEN = 128\n",
    "NUM_CLASSES = 4  # step1-step4\n",
    "THRESHOLD = 0.85\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------Transform---------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# -----------------Load CNN----------------------\n",
    "cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "cnn = nn.Sequential(*list(cnn.children())[:-1])  # remove final FC\n",
    "cnn.eval().to(device)\n",
    "\n",
    "# ----------------- Feature extraction -----------\n",
    "def extract_segment_features(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        if count % FRAME_SKIP == 0:\n",
    "            img = transform(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                feat = cnn(img).squeeze().cpu().numpy()\n",
    "            frames.append(feat)\n",
    "        count += 1\n",
    "    cap.release()\n",
    "\n",
    "    frames = np.array(frames)\n",
    "    total_segments = NUM_REPS * STEPS_PER_REP\n",
    "    segment_len = max(len(frames) // total_segments, 1)\n",
    "    segments = []\n",
    "    for i in range(total_segments):\n",
    "        start = i * segment_len\n",
    "        end = start + segment_len\n",
    "        seg = frames[start:end]\n",
    "        if len(seg) == 0:\n",
    "            seg = frames[-1:].copy()  # repeat last frame if empty\n",
    "        segments.append(seg)\n",
    "    return segments\n",
    "\n",
    "# -----------------LSTM Classifier-----------------\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_size=LSTM_HIDDEN, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n.squeeze(0))\n",
    "        return out\n",
    "\n",
    "# ----------------- Load trained LSTM -----------------\n",
    "lstm_model = LSTMClassifier(input_size=512, hidden_size=LSTM_HIDDEN, num_classes=NUM_CLASSES).to(device)\n",
    "lstm_path = r\"C:\\Users\\sinch\\ai\\lstm_model.pth\"\n",
    "\n",
    "if os.path.exists(lstm_path):\n",
    "    checkpoint = torch.load(lstm_path, map_location=device)\n",
    "    # Load LSTM weights only\n",
    "    filtered_dict = {k: v for k, v in checkpoint.items() if k.startswith(\"lstm.\")}\n",
    "    lstm_model.load_state_dict(filtered_dict, strict=False)\n",
    "    lstm_model.eval()\n",
    "    print(\"✅ Trained LSTM weights loaded successfully\")\n",
    "else:\n",
    "    print(\"⚠️ LSTM weights not found — using random initialization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eff065e-5db0-465d-8033-0e439f5b1a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinch\\AppData\\Local\\Temp\\ipykernel_21608\\2081138761.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out = lstm_model.fc(torch.tensor(h_n.squeeze(0)).to(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Built reference from 5 videos -> reference_steps.npy\n",
      "✅ Built sequence reference from 5 videos -> reference_sequences.npy\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Encode video with LSTM -------\n",
    "def encode_segments_with_lstm(segments):\n",
    "    segment_features = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for seg in segments:\n",
    "        seg = np.array(seg)\n",
    "        seg_avg = seg.mean(axis=0)\n",
    "        inp = torch.tensor(seg_avg, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            _, (h_n, _) = lstm_model.lstm(inp)\n",
    "            feat = h_n.squeeze(0).cpu().numpy().reshape(-1)\n",
    "            out = lstm_model.fc(torch.tensor(h_n.squeeze(0)).to(device))\n",
    "            pred = torch.argmax(out, dim=1).item()\n",
    "        segment_features.append(feat)\n",
    "        predicted_labels.append(pred + 1)\n",
    "    return np.array(segment_features), predicted_labels\n",
    "\n",
    "# ----------------- Sequence & Step analysis -----------------\n",
    "def check_sequence_order(predicted_labels):\n",
    "    correct_order = []\n",
    "    total_reps = len(predicted_labels) // STEPS_PER_REP\n",
    "    for rep in range(total_reps):\n",
    "        start = rep * STEPS_PER_REP\n",
    "        seq = predicted_labels[start:start + STEPS_PER_REP]\n",
    "        correct_order.append(seq == list(range(1, STEPS_PER_REP + 1)))\n",
    "    return correct_order\n",
    "\n",
    "def step_similarity_analysis(features_array):\n",
    "    similarities = []\n",
    "    for step in range(STEPS_PER_REP):\n",
    "        idxs = [step + rep * STEPS_PER_REP for rep in range(NUM_REPS)]\n",
    "        feats = features_array[idxs].reshape(len(idxs), -1)\n",
    "        sims = cosine_similarity(feats)\n",
    "        similarities.append(sims)\n",
    "    return np.array(similarities)\n",
    "\n",
    "def classify_steps(features_array, threshold=THRESHOLD):\n",
    "    step_status = {}\n",
    "    ground_truth = {}\n",
    "    predictions = {}\n",
    "    for step in range(STEPS_PER_REP):\n",
    "        idxs = [step + rep * STEPS_PER_REP for rep in range(NUM_REPS)]\n",
    "        feats = features_array[idxs].reshape(len(idxs), -1)\n",
    "        sims = cosine_similarity(feats)\n",
    "        avg_sim = np.mean([sims[i, j] for i in range(NUM_REPS) for j in range(i + 1, NUM_REPS)])\n",
    "        step_status[step + 1] = 'Correct' if avg_sim >= threshold else 'Incorrect'\n",
    "        ground_truth[step + 1] = 'Correct'\n",
    "        predictions[step + 1] = step_status[step + 1]\n",
    "    return step_status, ground_truth, predictions\n",
    "\n",
    "# ----------------- Build reference from multiple videos -----------------\n",
    "def build_reference_from_multiple(videos, save_path=\"reference_steps.npy\"):\n",
    "    all_refs = []\n",
    "    for video_path in videos:\n",
    "        segments = extract_segment_features(video_path)\n",
    "        ref_feats, _ = encode_segments_with_lstm(segments)\n",
    "        all_refs.append(ref_feats)\n",
    "    all_refs = np.stack(all_refs)\n",
    "    refs = []\n",
    "    for step in range(STEPS_PER_REP):\n",
    "        step_vecs = []\n",
    "        for vid in range(all_refs.shape[0]):\n",
    "            idxs = [step + rep * STEPS_PER_REP for rep in range(NUM_REPS)]\n",
    "            step_vecs.extend(all_refs[vid, idxs])\n",
    "        refs.append(np.mean(step_vecs, axis=0))\n",
    "    reference_steps = np.array(refs)\n",
    "    np.save(save_path, reference_steps)\n",
    "    print(f\"✅ Built reference from {len(videos)} videos -> {save_path}\")\n",
    "    return reference_steps\n",
    "\n",
    "def build_reference_sequences(videos, save_path=\"reference_sequences.npy\"):\n",
    "    all_refs = []\n",
    "    for video_path in videos:\n",
    "        segments = extract_segment_features(video_path)\n",
    "        seq = np.concatenate(segments, axis=0)\n",
    "        inp = torch.tensor(seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            seq_feat, _ = lstm_model.lstm(inp)\n",
    "            seq_feat = seq_feat.squeeze(0).cpu().numpy().mean(axis=0)  # average over sequence\n",
    "        all_refs.append(seq_feat)\n",
    "    all_refs = np.array(all_refs)\n",
    "    np.save(save_path, all_refs)\n",
    "    print(f\"✅ Built sequence reference from {len(videos)} videos -> {save_path}\")\n",
    "    return all_refs\n",
    "\n",
    "# ----------------- Example videos -----------------\n",
    "videos = [\n",
    "    r\"C:\\Users\\sinch\\ai\\goldstandard1.mp4\",\n",
    "    r\"C:\\Users\\sinch\\ai\\goldstandard2.mp4\",\n",
    "    r\"C:\\Users\\sinch\\ai\\goldstandard3.mp4\",\n",
    "    r\"C:\\Users\\sinch\\ai\\goldstandard4.mp4\",\n",
    "    r\"C:\\Users\\sinch\\ai\\testvideo.mp4\"\n",
    "]\n",
    "\n",
    "reference_steps = build_reference_from_multiple(videos)\n",
    "reference_sequences = build_reference_sequences(videos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10720a23-b4d2-4af3-8c31-e86a6498d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Save weights/model \n",
    "torch.save(lstm_model.state_dict(), r\"C:\\Users\\sinch\\ai\\lstm_model.pth\")\n",
    "torch.save(cnn.state_dict(), r\"C:\\Users\\sinch\\ai\\cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c394ac-fc59-4c23-9a05-0b3bd76e7e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sinch\\anaconda3\\envs\\siri\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sinch\\anaconda3\\envs\\siri\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSTM model loaded successfully\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.774, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.775, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.776, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.778, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.779, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.781, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.783, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.785, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.787, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.789, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.792, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.795, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.800, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.805, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.809, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.811, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.812, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.815, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.815, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.816, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.817, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.822, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.820, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.815, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.812, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.811, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.812, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.814, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.816, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.820, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.823, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.822, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.821, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.820, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.820, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.822, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.825, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.828, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.835, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.840, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.841, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.839, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.839, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.837, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.834, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.831, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.824, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.822, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.823, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.822, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.817, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.816, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.810, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.806, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.796, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.804, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.805, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.807, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.808, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.807, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.804, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.802, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.799, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.800, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.802, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.799, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.800, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.802, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.804, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.804, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.805, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.802, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.802, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.803, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.797, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.793, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.793, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.808, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.814, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.817, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.814, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.813, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.823, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.822, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.817, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.812, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.803, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.797, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.796, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.797, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.794, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.793, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.791, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.792, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.792, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.795, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.800, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.803, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.805, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.807, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.810, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.807, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.803, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.797, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.793, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.790, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.786, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.784, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.783, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.783, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.783, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.784, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.787, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.789, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.792, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.796, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.804, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.806, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.811, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.813, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.820, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.821, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.820, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.821, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.818, Status: ❌ Incorrect sequence! Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.815, Status: ❌ Incorrect sequence! Missed Step 1\n"
     ]
    }
   ],
   "source": [
    "# seq\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ================= CONFIG ==============\n",
    "FRAME_SKIP = 5          # sample every 5 frames\n",
    "SEQ_LEN = 12            # number of frames per sequence\n",
    "THRESHOLD = 0.75       # cosine similarity threshold\n",
    "NUM_STEPS = 4           # total steps in the sequence\n",
    "\n",
    "# ---------------- Device ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---------------- CNN Model ----------------\n",
    "cnn_model = models.resnet18(pretrained=True)\n",
    "cnn_model = torch.nn.Sequential(*list(cnn_model.children())[:-1])  # remove FC\n",
    "cnn_model.eval().to(device)\n",
    "\n",
    "# ---------------- LSTM Feature Extractor ----------------\n",
    "class LSTMFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return h_n.squeeze(0)\n",
    "\n",
    "# Load LSTM weights\n",
    "lstm_model = LSTMFeatureExtractor(input_size=512, hidden_size=128).to(device)\n",
    "checkpoint = torch.load(r\"C:\\Users\\sinch\\ai\\lstm_model.pth\", map_location=device)\n",
    "filtered_dict = {k: v for k, v in checkpoint.items() if not k.startswith(\"fc.\")}\n",
    "lstm_model.load_state_dict(filtered_dict, strict=False)\n",
    "lstm_model.eval()\n",
    "print(\"✅ LSTM model loaded successfully\")\n",
    "\n",
    "# ---------------- Reference Features ----------------\n",
    "reference_features = np.load(\"reference_sequences.npy\")  # shape: [num_steps, hidden_size]\n",
    "\n",
    "# ---------------- Transform ----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ---------------- Live Loop ----------------\n",
    "url = r\"rtsp://admin:admin%40123@192.168.0.171/cam/realmonitor?channel=1&subtype=0\"\n",
    "cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "current_step = 0  # index of current step (0..NUM_STEPS-1)\n",
    "detected_steps = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Run LSTM when buffer is full\n",
    "    if len(frame_buffer) >= SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer[-SEQ_LEN:]), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        # Cosine similarity with reference steps\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        # Determine status\n",
    "        if max_sim >= THRESHOLD:\n",
    "            if best_step == current_step:\n",
    "                status = f\"Step {best_step+1} ✅\"\n",
    "                if best_step not in detected_steps:\n",
    "                    detected_steps.append(best_step)\n",
    "                current_step += 1 if current_step < NUM_STEPS-1 else 0\n",
    "            else:\n",
    "                status = f\"❌ Incorrect sequence! Missed Step {current_step+1}\"\n",
    "        else:\n",
    "            status = f\"❌ Step unclear / sequence skipped\"\n",
    "\n",
    "        color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "        cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "        print(f\"[DEBUG] Detected step: {best_step+1}, Max similarity: {max_sim:.3f}, Status: {status}\")\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bc229b-4163-477a-8388-4a1f0ab07de4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ---------------- Live Loop ----------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrtsp://admin:admin\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m40123@192.168.0.171/cam/realmonitor?channel=1&subtype=0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(url, cv2\u001b[38;5;241m.\u001b[39mCAP_FFMPEG)\n\u001b[0;32m      4\u001b[0m frame_buffer \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m frame_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------------- Live Loop ----------------\n",
    "url = r\"rtsp://admin:admin%40123@192.168.0.171/cam/realmonitor?channel=1&subtype=0\"\n",
    "cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "expected_step = 0  # start from step 0\n",
    "last_status_type = None  # \"inorder\", \"outoforder\", \"unclear\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Run LSTM when buffer is full\n",
    "    if len(frame_buffer) >= SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer[-SEQ_LEN:]), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        # Cosine similarity with reference steps\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        if max_sim >= THRESHOLD:\n",
    "            if best_step == expected_step:\n",
    "                status = f\"✅ Step {best_step+1} detected in order\"\n",
    "                expected_step = (expected_step + 1) % NUM_STEPS\n",
    "                last_status_type = \"inorder\"\n",
    "            else:\n",
    "                if last_status_type != \"outoforder\":\n",
    "                    status = f\"⚠️ Out of order: Detected Step {best_step+1}, Expected Step {expected_step+1}\"\n",
    "                    beep()\n",
    "                    last_status_type = \"outoforder\"\n",
    "                else:\n",
    "                    status = f\"Detected Step {best_step+1}\"  # show only detection\n",
    "        else:\n",
    "            status = \"❌ Unclear / No valid step\"\n",
    "            last_status_type = \"unclear\"\n",
    "\n",
    "        color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "        cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "        print(f\"[DEBUG] Detected: {best_step+1}, Similarity: {max_sim:.3f}, Status: {status}\")\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef40fc3-3943-4a61-8af6-5239e327a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- CONFIG ----------------\n",
    "FRAME_SKIP = 2         # sample every 2 frames (more frequent)\n",
    "SEQ_LEN = 12           # number of frames per sequence\n",
    "THRESHOLD = 0.75       # similarity threshold\n",
    "MIN_CONSECUTIVE = 2    # frames needed to confirm a step\n",
    "\n",
    "# ---------------- Live Loop ----------------\n",
    "url = r\"rtsp://admin:admin%40123@192.168.0.171/cam/realmonitor?channel=1&subtype=0\"\n",
    "cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "last_reported_step = None\n",
    "current_detected = None\n",
    "consecutive_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Keep only last SEQ_LEN frames\n",
    "    if len(frame_buffer) > SEQ_LEN:\n",
    "        frame_buffer.pop(0)\n",
    "\n",
    "    if len(frame_buffer) == SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        # Consecutive detection logic\n",
    "        if max_sim >= THRESHOLD:\n",
    "            if current_detected == best_step:\n",
    "                consecutive_count += 1\n",
    "            else:\n",
    "                current_detected = best_step\n",
    "                consecutive_count = 1\n",
    "\n",
    "            if consecutive_count >= MIN_CONSECUTIVE and current_detected != last_reported_step:\n",
    "                status = f\"✅ Step {current_detected+1} detected\"\n",
    "                last_reported_step = current_detected\n",
    "                consecutive_count = 0\n",
    "                color = (0,255,0)\n",
    "                cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                print(f\"[DEBUG] Detected: {current_detected+1}, Similarity: {max_sim:.3f}, Status: {status}\")\n",
    "        else:\n",
    "            current_detected = None\n",
    "            consecutive_count = 0\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6734ab-cd31-4e21-88cd-ef223d68b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stream opened\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "url = r\"rtsp://admin:admin%40123@192.168.0.171/cam/realmonitor?channel=1&subtype=0\"\n",
    "cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Cannot open RTSP\")\n",
    "else:\n",
    "    print(\"✅ Stream opened\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"❌ Failed to grab frame\")\n",
    "            break\n",
    "        cv2.imshow(\"RTSP Stream\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a1e03-08b6-41e2-9c94-8ebaf342a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Live Loop ----------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ================= CONFIG ==============\n",
    "FRAME_SKIP = 5          # sample every 5 frames\n",
    "SEQ_LEN = 12            # number of frames per sequence\n",
    "THRESHOLD = 0.80       # cosine similarity threshold\n",
    "NUM_STEPS = 4           # total steps in the sequence\n",
    "\n",
    "# ---------------- Device ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---------------- CNN Model ----------------\n",
    "cnn_model = models.resnet18(pretrained=True)\n",
    "cnn_model = torch.nn.Sequential(*list(cnn_model.children())[:-1])  # remove FC\n",
    "cnn_model.eval().to(device)\n",
    "\n",
    "# ---------------- LSTM Feature Extractor ----------------\n",
    "class LSTMFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return h_n.squeeze(0)\n",
    "\n",
    "# Load LSTM weights\n",
    "lstm_model = LSTMFeatureExtractor(input_size=512, hidden_size=128).to(device)\n",
    "checkpoint = torch.load(r\"C:\\Users\\sinch\\ai\\lstm_model.pth\", map_location=device)\n",
    "filtered_dict = {k: v for k, v in checkpoint.items() if not k.startswith(\"fc.\")}\n",
    "lstm_model.load_state_dict(filtered_dict, strict=False)\n",
    "lstm_model.eval()\n",
    "print(\"✅ LSTM model loaded successfully\")\n",
    "\n",
    "# ---------------- Reference Features ----------------\n",
    "reference_features = np.load(\"reference_sequences.npy\")  # shape: [num_steps, hidden_size]\n",
    "\n",
    "# ---------------- Transform ----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "url = r\"rtsp://admin:admin%40123@192.168.0.171/cam/realmonitor?channel=1&subtype=0\"\n",
    "cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "expected_step = 0      # which step should come next\n",
    "last_reported_step = None  # avoid repeating messages\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Keep only last SEQ_LEN frames\n",
    "    if len(frame_buffer) > SEQ_LEN:\n",
    "        frame_buffer.pop(0)\n",
    "\n",
    "    if len(frame_buffer) == SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        status = None\n",
    "\n",
    "        if max_sim >= THRESHOLD and best_step != last_reported_step:\n",
    "            if best_step == expected_step:\n",
    "                # Step detected in order\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "            elif best_step > expected_step:\n",
    "                # Step ahead, assume intermediate steps passed\n",
    "                status = f\"✅ Step {best_step+1} detected (intermediate assumed)\"\n",
    "            else:\n",
    "                # Step behind, ignore repeated / holding frames\n",
    "                status = f\"✅ Step {best_step+1} detected (holding/repeated)\"\n",
    "\n",
    "            # Update expected step for next detection\n",
    "            expected_step = (best_step + 1) % NUM_STEPS\n",
    "            last_reported_step = best_step\n",
    "\n",
    "        if status:\n",
    "            color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "            cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            print(f\"[DEBUG] {status}, Similarity: {max_sim:.3f}\")\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c847324-40b1-4814-ba55-608f5a5f3761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sinch\\anaconda3\\envs\\siri\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sinch\\anaconda3\\envs\\siri\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSTM model loaded successfully\n",
      "[DEBUG] ⚠️ Missed Step(s), Jumped to Step 5, Similarity: 0.756\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.757\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.758\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.761\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.767\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.770\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.770\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.773\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.775\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.780\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.780\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.782\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.786\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.792\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.796\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.795\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.798\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.803\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.808\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.809\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.807\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.807\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.808\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.809\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.809\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.797\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.787\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.781\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.783\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.790\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.803\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.810\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.812\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.819\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.827\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.822\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.814\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.801\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.795\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.793\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.792\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.791\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.794\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.796\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.798\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.799\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.799\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.798\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.798\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.799\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.798\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.796\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.792\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.781\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.772\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.770\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.771\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.773\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.774\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.774\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.777\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.782\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.788\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.789\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.788\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.785\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.783\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.780\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.777\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.775\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.774\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.773\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.770\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.768\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.768\n",
      "[DEBUG] ✅ Step 5 detected (holding/intermediate), Similarity: 0.766\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Live Loop ----------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ================= CONFIG ==============\n",
    "FRAME_SKIP = 5          # sample every 5 frames\n",
    "SEQ_LEN = 12            # number of frames per sequence\n",
    "THRESHOLD = 0.75       # cosine similarity threshold\n",
    "NUM_STEPS = 4           # total steps in the sequence\n",
    "\n",
    "# ---------------- Device ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---------------- CNN Model ----------------\n",
    "cnn_model = models.resnet18(pretrained=True)\n",
    "cnn_model = torch.nn.Sequential(*list(cnn_model.children())[:-1])  # remove FC\n",
    "cnn_model.eval().to(device)\n",
    "\n",
    "# ---------------- LSTM Feature Extractor ----------------\n",
    "class LSTMFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return h_n.squeeze(0)\n",
    "\n",
    "# Load LSTM weights\n",
    "lstm_model = LSTMFeatureExtractor(input_size=512, hidden_size=128).to(device)\n",
    "checkpoint = torch.load(r\"C:\\Users\\sinch\\ai\\lstm_model.pth\", map_location=device)\n",
    "filtered_dict = {k: v for k, v in checkpoint.items() if not k.startswith(\"fc.\")}\n",
    "lstm_model.load_state_dict(filtered_dict, strict=False)\n",
    "lstm_model.eval()\n",
    "print(\"✅ LSTM model loaded successfully\")\n",
    "\n",
    "# ---------------- Reference Features ----------------\n",
    "reference_features = np.load(\"reference_sequences.npy\")  # shape: [num_steps, hidden_size]\n",
    "\n",
    "# ---------------- Transform ----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "url = r\"rtsp://admin:admin%40123@192.168.0.171/cam/realmonitor?channel=1&subtype=0\"\n",
    "\n",
    "cap = cv2.VideoCapture(url, cv2.CAP_FFMPEG)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "expected_step = 0      # which step should come next\n",
    "last_reported_step = None  # avoid repeating messages\n",
    "skipped_reported = False   # to show skipped warning only once\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    if len(frame_buffer) > SEQ_LEN:\n",
    "        frame_buffer.pop(0)\n",
    "\n",
    "    if len(frame_buffer) == SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        status = None\n",
    "\n",
    "        if max_sim >= THRESHOLD:\n",
    "            # Step detected in order\n",
    "            if best_step == expected_step:\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "                expected_step = (expected_step + 1) % NUM_STEPS\n",
    "                skipped_reported = False\n",
    "            # Step ahead\n",
    "            elif best_step > expected_step:\n",
    "                if not skipped_reported:\n",
    "                    status = f\"⚠️ Missed Step(s), Jumped to Step {best_step+1}\"\n",
    "                    skipped_reported = True\n",
    "                else:\n",
    "                    status = f\"✅ Step {best_step+1} detected (holding/intermediate)\"\n",
    "                expected_step = (best_step + 1) % NUM_STEPS\n",
    "            # Step behind (holding)\n",
    "            else:\n",
    "                status = f\"✅ Step {best_step+1} detected (holding/repeated)\"\n",
    "\n",
    "            last_reported_step = best_step\n",
    "\n",
    "        if status:\n",
    "            color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "            cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            print(f\"[DEBUG] {status}, Similarity: {max_sim:.3f}\")\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084a72d7-436a-4814-be73-981671b753c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sinch\\anaconda3\\envs\\siri\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sinch\\anaconda3\\envs\\siri\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSTM model loaded successfully\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.787, Status: ❌ Missed Step 1\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.790, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.798, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.802, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.806, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.804, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.799, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.788, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.797, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.797, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.799, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.807, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.789, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.801, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.799, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.784, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.788, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.780, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.758, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.767, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.774, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.805, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.791, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.783, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.770, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.749, Status: ❌ Step unclear / sequence skipped\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.765, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.782, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.773, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.779, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.784, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 5, Max similarity: 0.761, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.750, Status: ❌ Step unclear / sequence skipped\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.750, Status: ❌ Step unclear / sequence skipped\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.767, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.767, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.785, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.772, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.775, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.778, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.774, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.775, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.781, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.780, Status: Waiting for Step 2...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.789, Status: Step 2 ✅\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.832, Status: ❌ Missed Step 3\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.844, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.827, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.815, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.811, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.799, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.800, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.789, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.791, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.796, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 2, Max similarity: 0.797, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.803, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.794, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.792, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.789, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.790, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.798, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.806, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.807, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.803, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.803, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.804, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.805, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.810, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.807, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.801, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.792, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.782, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.776, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.773, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.765, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.761, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.759, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.755, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.751, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.747, Status: ❌ Step unclear / sequence skipped\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.749, Status: ❌ Step unclear / sequence skipped\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.758, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.755, Status: Waiting for Step 4...\n",
      "[DEBUG] Detected step: 3, Max similarity: 0.761, Status: Waiting for Step 4...\n"
     ]
    }
   ],
   "source": [
    "# seq\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import platform\n",
    "\n",
    "# ================= CONFIG ==============\n",
    "FRAME_SKIP = 5          # sample every 5 frames\n",
    "SEQ_LEN = 12            # number of frames per sequence\n",
    "THRESHOLD = 0.75        # cosine similarity threshold\n",
    "NUM_STEPS = 4           # total steps in the sequence\n",
    "\n",
    "# ---------------- Device ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---------------- CNN Model ----------------\n",
    "cnn_model = models.resnet18(pretrained=True)\n",
    "cnn_model = torch.nn.Sequential(*list(cnn_model.children())[:-1])  # remove FC\n",
    "cnn_model.eval().to(device)\n",
    "\n",
    "# ---------------- LSTM Feature Extractor ----------------\n",
    "class LSTMFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_size=128, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return h_n.squeeze(0)\n",
    "\n",
    "# Load LSTM weights\n",
    "lstm_model = LSTMFeatureExtractor(input_size=512, hidden_size=128).to(device)\n",
    "checkpoint = torch.load(r\"C:\\Users\\sinch\\ai\\lstm_model.pth\", map_location=device)\n",
    "filtered_dict = {k: v for k, v in checkpoint.items() if not k.startswith(\"fc.\")}\n",
    "lstm_model.load_state_dict(filtered_dict, strict=False)\n",
    "lstm_model.eval()\n",
    "print(\"✅ LSTM model loaded successfully\")\n",
    "\n",
    "# ---------------- Reference Features ----------------\n",
    "reference_features = np.load(\"reference_sequences.npy\")  # shape: [num_steps, hidden_size]\n",
    "\n",
    "# ---------------- Transform ----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ---------------- Optional Beep ----------------\n",
    "def beep():\n",
    "    if platform.system() == \"Windows\":\n",
    "        import winsound\n",
    "        winsound.Beep(1000, 200)  # freq=1000Hz, duration=200ms\n",
    "    else:\n",
    "        print(\"\\a\")  # fallback console beep\n",
    "\n",
    "# ---------------- Live Loop ----------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "current_step = 0  # index of current step (0..NUM_STEPS-1)\n",
    "detected_steps = []\n",
    "missed_flag = False  # to avoid spamming missed step messages\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Run LSTM when buffer is full\n",
    "    if len(frame_buffer) >= SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer[-SEQ_LEN:]), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        # Cosine similarity with reference steps\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        # Determine status\n",
    "        if max_sim >= THRESHOLD:\n",
    "            if best_step == current_step:\n",
    "                status = f\"Step {best_step+1} ✅\"\n",
    "                if best_step not in detected_steps:\n",
    "                    detected_steps.append(best_step)\n",
    "                current_step += 1 if current_step < NUM_STEPS-1 else 0\n",
    "                missed_flag = False  # reset missed state\n",
    "            else:\n",
    "                if not missed_flag:  # report only once\n",
    "                    status = f\"❌ Missed Step {current_step+1}\"\n",
    "                    beep()\n",
    "                    current_step += 1 if current_step < NUM_STEPS-1 else 0\n",
    "                    missed_flag = True\n",
    "                else:\n",
    "                    status = f\"Waiting for Step {current_step+1}...\"\n",
    "        else:\n",
    "            status = f\"❌ Step unclear / sequence skipped\"\n",
    "\n",
    "        color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "        cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "        print(f\"[DEBUG] Detected step: {best_step+1}, Max similarity: {max_sim:.3f}, Status: {status}\")\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "296f7b6d-1f09-41e9-9cc9-5d093a28073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ❌ Missed Step 1, Detected Step 2, Similarity: 0.790\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.794\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.800\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.816\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.837\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.844\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.849\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.832\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.830\n",
      "[DEBUG] ❌ Missed Step 4, Detected Step 5, Similarity: 0.844\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Live Loop ----------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "current_step = 0  # index of current step (0..NUM_STEPS-1)\n",
    "detected_steps = []\n",
    "missed_flag = False  # to avoid repeating missed step messages\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Keep only last SEQ_LEN frames\n",
    "    if len(frame_buffer) > SEQ_LEN:\n",
    "        frame_buffer.pop(0)\n",
    "\n",
    "    if len(frame_buffer) == SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        # Cosine similarity with reference steps\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        status = None\n",
    "\n",
    "        if max_sim >= THRESHOLD:\n",
    "            if best_step == current_step:\n",
    "                # Step detected in order\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "                detected_steps.append(best_step)\n",
    "                current_step += 1 if current_step < NUM_STEPS-1 else 0\n",
    "                missed_flag = False\n",
    "            elif best_step > current_step:\n",
    "                # Step skipped\n",
    "                if not missed_flag:\n",
    "                    status = f\"❌ Missed Step {current_step+1}, Detected Step {best_step+1}\"\n",
    "                    beep()\n",
    "                    detected_steps.append(best_step)\n",
    "                    current_step = best_step + 1 if best_step < NUM_STEPS-1 else 0\n",
    "                    missed_flag = True\n",
    "            else:\n",
    "                # Step behind / holding, ignore\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "\n",
    "            # Only print new status\n",
    "            if status:\n",
    "                color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "                cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                print(f\"[DEBUG] {status}, Similarity: {max_sim:.3f}\")\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd0274f-45d5-4bcd-9df6-641d50bdd967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ❌ Missed Step 1, Detected Step 5, Similarity: 0.830\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.829\n",
      "[DEBUG] ❌ Missed Step 2, Detected Step 3, Similarity: 0.847\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.846\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.850\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.866\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.882\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.865\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.845\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.844\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.844\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.860\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.863\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.861\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.849\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.850\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.852\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.860\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.854\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.853\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.849\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.838\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.826\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.820\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.809\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.819\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.814\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.813\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.817\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.831\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.842\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.834\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.835\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.841\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.847\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.838\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.840\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.848\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.855\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.852\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.852\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.845\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.834\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.847\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.849\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.836\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.825\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.823\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.833\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.830\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.837\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.842\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.844\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.838\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.833\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.832\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.843\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.849\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.861\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.852\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.859\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.878\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.890\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.888\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.881\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.874\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.860\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.855\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.858\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.866\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.886\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.895\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.899\n",
      "[DEBUG] ✅ Step 2 detected, Similarity: 0.895\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Live Loop ----------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "current_step = 0  # index of current step (0..NUM_STEPS-1)\n",
    "detected_steps = []\n",
    "missed_flag = False  # to avoid repeating missed step messages\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Keep only last SEQ_LEN frames\n",
    "    if len(frame_buffer) > SEQ_LEN:\n",
    "        frame_buffer.pop(0)\n",
    "\n",
    "    if len(frame_buffer) == SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        # Cosine similarity with reference steps\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        status = None\n",
    "\n",
    "        if max_sim >= THRESHOLD:\n",
    "            if best_step == current_step:\n",
    "                # Step detected in order\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "                detected_steps.append(best_step)\n",
    "                current_step += 1 if current_step < NUM_STEPS-1 else 0\n",
    "                missed_flag = False\n",
    "            elif best_step > current_step:\n",
    "                # Step skipped\n",
    "                if not missed_flag:\n",
    "                    status = f\"❌ Missed Step {current_step+1}, Detected Step {best_step+1}\"\n",
    "                    beep()\n",
    "                    detected_steps.append(best_step)\n",
    "                    current_step = best_step + 1 if best_step < NUM_STEPS-1 else 0\n",
    "                    missed_flag = True\n",
    "            else:\n",
    "                # Step behind / holding, ignore\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "\n",
    "            # Only print new status\n",
    "            if status:\n",
    "                color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "                cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                print(f\"[DEBUG] {status}, Similarity: {max_sim:.3f}\")\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d731380f-999b-4016-931c-27c610fea236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "def beep():\n",
    "    playsound(\"mixkit-facility-alarm-sound-999.wav\")  # Replace with path if in different folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc68d4fd-e8a2-4e90-b1aa-8c9d3a79dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "\n",
    "def beep():\n",
    "    winsound.PlaySound(\"SystemExclamation\", winsound.SND_ALIAS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be745450-e3c5-4d41-9a39-b45285766d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file = \"mixkit-facility-alarm-sound-999.wav\"\n",
    "print(os.path.exists(file))  # Should print True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83540932-0b75-441f-9473-d20e81b3a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "def beep():\n",
    "    fs = 44100  # sample rate\n",
    "    duration = 1 # seconds\n",
    "    f = 1000  # Hz\n",
    "    t = np.linspace(0, duration, int(fs*duration), False)\n",
    "    tone = 1 * np.sin(2 * np.pi * f * t)\n",
    "    sd.play(tone, fs)\n",
    "    sd.wait()\n",
    "\n",
    "# Test\n",
    "for _ in range(2):\n",
    "    beep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "86e4b3da-40dc-417f-90a2-fff9468167aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ❌ Missed Step 1, Detected Step 3, Similarity: 0.821\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.828\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.827\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.847\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.864\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.866\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.865\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.852\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.860\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.846\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.830\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.825\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.795\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.786\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.799\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.818\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.838\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.827\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.827\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.825\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.824\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.827\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.817\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.812\n",
      "[DEBUG] ✅ Step 1 detected, Similarity: 0.781\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.814\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.810\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.808\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.802\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.809\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.814\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.817\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.818\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.817\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.823\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.823\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.828\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.826\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.822\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.823\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.831\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.826\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.820\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.818\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.815\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.811\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.806\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.801\n",
      "[DEBUG] ✅ Step 4 detected, Similarity: 0.796\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.786\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.768\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.750\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.760\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.767\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.778\n",
      "[DEBUG] ✅ Step 3 detected, Similarity: 0.784\n",
      "[DEBUG] ❌ Missed Step 4, Detected Step 5, Similarity: 0.772\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import sounddevice as sd\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "FRAME_SKIP = 5          # sample every 5 frames\n",
    "SEQ_LEN = 12            # number of frames per sequence\n",
    "THRESHOLD = 0.75        # cosine similarity threshold\n",
    "NUM_STEPS = 4           # total steps in the sequence\n",
    "\n",
    "# ---------------- Beep function ----------------\n",
    "def beep():\n",
    "    fs = 44100  # sample rate\n",
    "    duration = 0.5  # seconds\n",
    "    f = 1000  # Hz\n",
    "    t = np.linspace(0, duration, int(fs*duration), False)\n",
    "    tone = 1 * np.sin(2 * np.pi * f * t)\n",
    "    sd.play(tone, fs)\n",
    "    sd.wait()\n",
    "\n",
    "# ---------------- Live Loop ----------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "current_step = 0  # index of current step (0..NUM_STEPS-1)\n",
    "detected_steps = []\n",
    "missed_flag = False  # to avoid repeating missed step messages\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Preprocess frame\n",
    "    img = transform(frame).unsqueeze(0).to(device)\n",
    "\n",
    "    # CNN feature extraction\n",
    "    with torch.no_grad():\n",
    "        cnn_feat = cnn_model(img).squeeze().cpu().numpy()\n",
    "    frame_buffer.append(cnn_feat)\n",
    "\n",
    "    # Keep only last SEQ_LEN frames\n",
    "    if len(frame_buffer) > SEQ_LEN:\n",
    "        frame_buffer.pop(0)\n",
    "\n",
    "    if len(frame_buffer) == SEQ_LEN:\n",
    "        seq_input = torch.tensor(np.array(frame_buffer), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            live_feat = lstm_model(seq_input).cpu().numpy().reshape(-1)\n",
    "\n",
    "        # Cosine similarity with reference steps\n",
    "        sims = cosine_similarity(live_feat.reshape(1,-1), reference_features)\n",
    "        best_step = sims.argmax()\n",
    "        max_sim = sims.max()\n",
    "\n",
    "        status = None\n",
    "\n",
    "        if max_sim >= THRESHOLD:\n",
    "            if best_step == current_step:\n",
    "                # Step detected in order\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "                detected_steps.append(best_step)\n",
    "                current_step += 1 if current_step < NUM_STEPS-1 else 0\n",
    "                missed_flag = False\n",
    "            elif best_step > current_step:\n",
    "                # Step skipped\n",
    "                if not missed_flag:\n",
    "                    status = f\"❌ Missed Step {current_step+1}, Detected Step {best_step+1}\"\n",
    "                    # Play beep in a separate thread\n",
    "                    threading.Thread(target=beep).start()\n",
    "                    detected_steps.append(best_step)\n",
    "                    current_step = best_step + 1 if best_step < NUM_STEPS-1 else 0\n",
    "                    missed_flag = True\n",
    "            else:\n",
    "                # Step behind / holding, ignore\n",
    "                status = f\"✅ Step {best_step+1} detected\"\n",
    "\n",
    "            # Display status\n",
    "            if status:\n",
    "                color = (0,255,0) if \"✅\" in status else (0,0,255)\n",
    "                cv2.putText(frame, status, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                print(f\"[DEBUG] {status}, Similarity: {max_sim:.3f}\")\n",
    "\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89c509-37b6-44da-8db8-2a87bf46b301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93017f48-f190-41d6-b6d7-d1c8d397beed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (siri)",
   "language": "python",
   "name": "siri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
